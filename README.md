# Reddit Flair Detector App
### A basic Flask app to detect the flair of reddit post in r/india subreddit.

**[Link TO Live App](https://flairfetector.herokuapp.com/)**

## Technology Used
1. Flask
2. Praw (For Scrapping Reddit Data)
3. MongoDB
4. Graph.js
5. Heroku

## How To Use
1. clone the git repository
2. Install all the requirements using requirements.txt *pip install -r requirements.txt* (recommended via virtual env)
3. Install and setup MongoDB.
4. Download **stopwords** using nltk.txt file or simply run nltk.download('stopwords') in python shell.
5. Run app.py

## What is What?
1. *Data* folder contains the data set on which the ML models were applied.
2. *Data Extraction* folder has three jupyter notebook files. 
    1. The first file scrapped the data and uploaded it to a local mongodb instance.
    2. The MongoDBTestTrain file tested the dataset on all the models and found me the best fit.
    3. The LetsDoit file includes some of data manipulation that is used to make the interactive graphs (more about them later)
3. *Supporter* folder has a reddit file that helps predict the data on the link given by the user
4. *Static* and *Template* folder include html/js/css files for the web pages

## How did I go about it.
Since this task was something new for me and i hadn't worked on any machine learning model before. I got to learn a lot. Especially working with MongoDB and learning about text pre-processing. I have used SVM, Linear Logistics, Naive Bayes, XGBoost. to create vectors, i have tried pipelining count-vector with tfidf-transform and tfidf-vector with tfidf-transform. I downloaded around 2650 posts combining all 11 flair categories. Then tried to combine features and test the accuracy.
1. Features used and tested:
    * Title
    * Comments (top 30)
    * Author
    * URL
    * Created (time)
2. For creating graphs I have used Graphs.js with Flask. So from MongoDB I am fetching the data processed in Jupyter, and using that to form the graphs. Graphs Can be seen at 
    1. **[Graph For mean](https://flairfetector.herokuapp.com/graphs?field=mean)** Average number of upvotes/Comments On each flair Post
    2. **[Graph For max](https://flairfetector.herokuapp.com/graphs?field=max)** Max number of upvotes/Comments one Post Per Flair

### I tried combinations of all these and have tabulated them below.
## Results

### Naive Bayes MultinomialNB on Individual

| Feature  | Model | Vector | Acuracy|
| ------------- | ------------- |------------- | ------------- |
|Title| NB| Count Vectors|  0.4937142857142857|
|Body| NB| Count Vectors|  0.1702857142857143|
|Comments|NB| Count Vectors|  0.344|
|Author| NB| Count Vectors|  0.3257142857142857|


### Logistic Regresseion on Individual
| Feature  | Model | Vector | Acuracy|
| ------------- | ------------- |------------- | ------------- |
|Title| LR| Count Vectors|  0.45714285714285713|
|Body| LR| Count Vectors|  0.2297142857142857|
|Comments|LR| Count Vector|  0.40685714285714286|
|Author|LR| Count Vectors|  0.32342857142857145|


### Random Forest Classification on Individual
| Feature  | Model | Vector | Acuracy|
| ------------- | ------------- |------------- | ------------- |
|Title| RF| Count Vectors:|  0.35428571428571426|
|Body|RF| Count Vectors:|  0.24914285714285714|
|Comments|RF| Count Vectors:|  0.2822857142857143|
|Author|RF| Count Vectors:|  0.31085714285714283|


### Title + Comments + Body + Created
| Model | Vector | Acuracy|
| ------------ |------------- | ------------- |
|LR|C-T| 0.61|
|LR|T-T|**0.62**|
|NB|C-T|0.32|
|NB|T-T|0.45|
|RF|C-T|0.37|
|RF|T-T|0.34|


### Title + COmments + Body + URL
| Model | Vector | Acuracy|
| ------------ |------------- | ------------- |
|LR|C-T| 0.59|
|LR|T-T|**0.62**|
|NB|C-T|0.40|
|NB|T-T|0.52|
|RF|C-T|0.34|
|RF|T-T|0.35|



##### These were the latest Accuracy but the one used in the app is one with 70%, there was a kind of fluctuation with the dataset, so whenever I had a high accuracy I'd convert that to model and save it. **modelTCBU-c2.pkl** means comibnation of Title, Comments(top 30), Body, and URL.

##### The testing was done on smaller dataset too, They had some good outputs better than the one stated in the table. But the best output was about 69% and it was for 2600 records.  The reason the others were neglected was, the one used now has all the new posts as well, so that means even if the comments are nil, the model is not biased towards that as more or less the dataset was mostly generated by comments alone. I had a test file which had at max 100 top comments, which again was going to be biased towards the comments to make predictions.

##### One thing worth noticing here is that Food and Scheduled posts have mere 30% accuracy.



# Resources
[For ML](https://www.analyticsvidhya.com/blog/2018/04/a-comprehensive-guide-to-understand-and-implement-text-classification-in-python/)
[Reddit Data Scraping](https://praw.readthedocs.io/en/latest/)
[Chart.js](https://pythonspot.com/flask-and-great-looking-charts-using-chart-js/)
[Chart.js 2](https://www.chartjs.org/samples/latest/)








