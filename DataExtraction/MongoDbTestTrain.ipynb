{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MongoClient('mongodb://127.0.0.1:27017/')\n",
    "db = client.reddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = db.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(list(collection.find()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df['_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>body</th>\n",
       "      <th>comments</th>\n",
       "      <th>flair</th>\n",
       "      <th>numComs</th>\n",
       "      <th>score</th>\n",
       "      <th>time</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>parvdave</td>\n",
       "      <td>I don't understand what difference it will mak...</td>\n",
       "      <td>This post has been marked [R]. Please help ke...</td>\n",
       "      <td>AskIndia</td>\n",
       "      <td>1243</td>\n",
       "      <td>505</td>\n",
       "      <td>2016-11-09 05:03:02</td>\n",
       "      <td>Eli5: What the abolition of 500 and 1000 rupee...</td>\n",
       "      <td>https://www.reddit.com/r/india/comments/5btv1v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>alphasayen</td>\n",
       "      <td>What are the best alternatives to condoms that...</td>\n",
       "      <td>Abstinence.\\n\\n(Cries virgin tears) Pull out ...</td>\n",
       "      <td>AskIndia</td>\n",
       "      <td>30</td>\n",
       "      <td>17</td>\n",
       "      <td>2019-07-20 21:36:47</td>\n",
       "      <td>What is the best alternative to condoms that y...</td>\n",
       "      <td>https://www.reddit.com/r/india/comments/cfjf1z...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sudroy</td>\n",
       "      <td>Anyone knows where to watch eagoler chokh and ...</td>\n",
       "      <td>If it's aschhe abar shobor, then that's avail...</td>\n",
       "      <td>AskIndia</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>2019-07-21 00:30:47</td>\n",
       "      <td>Bengali movies</td>\n",
       "      <td>https://www.reddit.com/r/india/comments/cfkmjb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bhayanak-aatma</td>\n",
       "      <td>This question is for all but more specifically...</td>\n",
       "      <td>Takeshi's castle in Javed Jaffrey voice.  Mad...</td>\n",
       "      <td>AskIndia</td>\n",
       "      <td>70</td>\n",
       "      <td>21</td>\n",
       "      <td>2019-07-08 02:39:43</td>\n",
       "      <td>What was your favourite TV serials growing up?</td>\n",
       "      <td>https://www.reddit.com/r/india/comments/ca6nqa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LifeWastedOnLiving</td>\n",
       "      <td>Given how there are different Career expectati...</td>\n",
       "      <td>[deleted] Have done that.\\nRelocated to anoth...</td>\n",
       "      <td>AskIndia</td>\n",
       "      <td>49</td>\n",
       "      <td>59</td>\n",
       "      <td>2019-07-16 01:30:24</td>\n",
       "      <td>Survey : How many of you guys(men) would fully...</td>\n",
       "      <td>https://www.reddit.com/r/india/comments/cdgkis...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               author                                               body  \\\n",
       "0            parvdave  I don't understand what difference it will mak...   \n",
       "1          alphasayen  What are the best alternatives to condoms that...   \n",
       "2              Sudroy  Anyone knows where to watch eagoler chokh and ...   \n",
       "3      bhayanak-aatma  This question is for all but more specifically...   \n",
       "4  LifeWastedOnLiving  Given how there are different Career expectati...   \n",
       "\n",
       "                                            comments     flair numComs score  \\\n",
       "0   This post has been marked [R]. Please help ke...  AskIndia    1243   505   \n",
       "1   Abstinence.\\n\\n(Cries virgin tears) Pull out ...  AskIndia      30    17   \n",
       "2   If it's aschhe abar shobor, then that's avail...  AskIndia       7     7   \n",
       "3   Takeshi's castle in Javed Jaffrey voice.  Mad...  AskIndia      70    21   \n",
       "4   [deleted] Have done that.\\nRelocated to anoth...  AskIndia      49    59   \n",
       "\n",
       "                  time                                              title  \\\n",
       "0  2016-11-09 05:03:02  Eli5: What the abolition of 500 and 1000 rupee...   \n",
       "1  2019-07-20 21:36:47  What is the best alternative to condoms that y...   \n",
       "2  2019-07-21 00:30:47                                     Bengali movies   \n",
       "3  2019-07-08 02:39:43     What was your favourite TV serials growing up?   \n",
       "4  2019-07-16 01:30:24  Survey : How many of you guys(men) would fully...   \n",
       "\n",
       "                                                 url  \n",
       "0  https://www.reddit.com/r/india/comments/5btv1v...  \n",
       "1  https://www.reddit.com/r/india/comments/cfjf1z...  \n",
       "2  https://www.reddit.com/r/india/comments/cfkmjb...  \n",
       "3  https://www.reddit.com/r/india/comments/ca6nqa...  \n",
       "4  https://www.reddit.com/r/india/comments/cdgkis...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn import decomposition, ensemble\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df =df.replace(np.nan, '', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2649 entries, 0 to 2648\n",
      "Data columns (total 9 columns):\n",
      "author      2649 non-null object\n",
      "body        2649 non-null object\n",
      "comments    2649 non-null object\n",
      "flair       2649 non-null object\n",
      "numComs     2649 non-null object\n",
      "score       2649 non-null object\n",
      "time        2649 non-null object\n",
      "title       2649 non-null object\n",
      "url         2649 non-null object\n",
      "dtypes: object(9)\n",
      "memory usage: 186.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['author', 'body', 'comments', 'flair', 'numComs', 'score', 'time',\n",
       "       'title', 'url'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = df.flair\n",
    "fTitle = df.title\n",
    "fBody = df.body\n",
    "fAuthor = df.author\n",
    "fNumComs = df.numComs\n",
    "fscore = df.score\n",
    "fComments = df.comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "xTrainTitle,xTestTitle,yTrainTitle,yTestTitle=train_test_split(fTitle,label,test_size=0.33)\n",
    "\n",
    "xTrainBody,xTestBody,yTrainBody,yTestBody=train_test_split(fBody,label,test_size=0.33)\n",
    "\n",
    "xTrainAuthor,xTestAuthor,yTrainAuthor,yTestAuthor=train_test_split(fAuthor,label,test_size=0.33)\n",
    "\n",
    "xTrainNum,xTestNum,yTrainNum,yTestNum=train_test_split(fNumComs,label,test_size=0.33)\n",
    "\n",
    "xTrainComments,xTestComments,yTrainComments,yTestComments=train_test_split(fComments,label,test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = preprocessing.LabelEncoder()\n",
    "yTrainTitle=encoder.fit_transform(yTrainTitle)\n",
    "yTestTitle = encoder.fit_transform(yTestTitle)\n",
    "\n",
    "yTrainBody=encoder.fit_transform(yTrainBody)\n",
    "yTestBody = encoder.fit_transform(yTestBody)\n",
    "\n",
    "yTrainAuthor=encoder.fit_transform(yTrainAuthor)\n",
    "yTestAuthor = encoder.fit_transform(yTestAuthor)\n",
    "\n",
    "yTrainComments=encoder.fit_transform(yTrainComments)\n",
    "yTestComments = encoder.fit_transform(yTestComments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect = CountVectorizer(analyzer='word',token_pattern=r'\\w{1,}',stop_words='english')\n",
    "count_vect.fit(fTitle)\n",
    "xTrct = count_vect.transform(xTrainTitle)\n",
    "xTect = count_vect.transform(xTestTitle)\n",
    "\n",
    "count_vect = CountVectorizer(analyzer='word',token_pattern=r'\\w{1,}',stop_words='english')\n",
    "count_vect.fit(fBody)\n",
    "xTrcb = count_vect.transform(xTrainBody)\n",
    "xTecb = count_vect.transform(xTestBody)\n",
    "\n",
    "count_vect = CountVectorizer(analyzer='word',token_pattern=r'\\w{1,}')\n",
    "count_vect.fit(fAuthor)\n",
    "xTrca = count_vect.transform(xTrainAuthor)\n",
    "xTeca = count_vect.transform(xTestAuthor)\n",
    "\n",
    "count_vect = CountVectorizer(analyzer='word',token_pattern=r'\\w{1,}',stop_words='english')\n",
    "count_vect.fit(fComments)\n",
    "xTrcc = count_vect.transform(xTrainComments)\n",
    "xTecc = count_vect.transform(xTestComments)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(classifier, feature_vector_train, label, feature_vector_valid,yTest, is_neural_net=False):\n",
    "    # fit the training dataset on the classifier\n",
    "    classifier.fit(feature_vector_train, label)\n",
    "    \n",
    "    # predict the labels on validation dataset\n",
    "    predictions = classifier.predict(feature_vector_valid)\n",
    "    \n",
    "    if is_neural_net:\n",
    "        predictions = predictions.argmax(axis=-1)\n",
    "    global Y_test\n",
    "    return metrics.accuracy_score(predictions,yTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title NB, Count Vectors:  0.4937142857142857\n",
      "Body NB, Count Vectors:  0.16228571428571428\n",
      "Comments, Count Vectors:  0.376\n",
      "Author, Count Vectors:  0.288\n"
     ]
    }
   ],
   "source": [
    "accuracy = train_model(naive_bayes.MultinomialNB(), xTrct, yTrainTitle, xTect,yTestTitle)\n",
    "print(\"Title NB, Count Vectors: \", accuracy)\n",
    "\n",
    "accuracy = train_model(naive_bayes.MultinomialNB(), xTrcb, yTrainBody, xTecb,yTestBody)\n",
    "print(\"Body NB, Count Vectors: \", accuracy)\n",
    "\n",
    "accuracy = train_model(naive_bayes.MultinomialNB(), xTrcc, yTrainComments, xTecc,yTestComments)\n",
    "print(\"Comments, Count Vectors: \", accuracy)\n",
    "\n",
    "accuracy = train_model(naive_bayes.MultinomialNB(), xTrca, yTrainAuthor, xTeca,yTestAuthor)\n",
    "print(\"Author, Count Vectors: \", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title NB, Count Vectors:  0.47085714285714286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\utsavs~1\\desktop\\reddit~1\\myenv\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\utsavs~1\\desktop\\reddit~1\\myenv\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Body NB, Count Vectors:  0.2057142857142857\n",
      "Comments, Count Vectors:  0.448\n",
      "Author, Count Vectors:  0.30857142857142855\n"
     ]
    }
   ],
   "source": [
    "# linear_model.LogisticRegression()\n",
    "accuracy = train_model(linear_model.LogisticRegression(), xTrct, yTrainTitle, xTect,yTestTitle)\n",
    "print(\"Title NB, Count Vectors: \", accuracy)\n",
    "\n",
    "accuracy = train_model(linear_model.LogisticRegression(), xTrcb, yTrainBody, xTecb,yTestBody)\n",
    "print(\"Body NB, Count Vectors: \", accuracy)\n",
    "\n",
    "accuracy = train_model(linear_model.LogisticRegression(), xTrcc, yTrainComments, xTecc,yTestComments)\n",
    "print(\"Comments, Count Vectors: \", accuracy)\n",
    "\n",
    "accuracy = train_model(linear_model.LogisticRegression(), xTrca, yTrainAuthor, xTeca,yTestAuthor)\n",
    "print(\"Author, Count Vectors: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\utsavs~1\\desktop\\reddit~1\\myenv\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title NB, Count Vectors:  0.38171428571428573\n",
      "Body NB, Count Vectors:  0.22057142857142858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\utsavs~1\\desktop\\reddit~1\\myenv\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "c:\\users\\utsavs~1\\desktop\\reddit~1\\myenv\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comments, Count Vectors:  0.29942857142857143\n",
      "Author, Count Vectors:  0.3017142857142857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\utsavs~1\\desktop\\reddit~1\\myenv\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "accuracy = train_model(ensemble.RandomForestClassifier(), xTrct, yTrainTitle, xTect,yTestTitle)\n",
    "print(\"Title NB, Count Vectors: \", accuracy)\n",
    "\n",
    "accuracy = train_model(ensemble.RandomForestClassifier(), xTrcb, yTrainBody, xTecb,yTestBody)\n",
    "print(\"Body NB, Count Vectors: \", accuracy)\n",
    "\n",
    "accuracy = train_model(ensemble.RandomForestClassifier(), xTrcc, yTrainComments, xTecc,yTestComments)\n",
    "print(\"Comments, Count Vectors: \", accuracy)\n",
    "\n",
    "accuracy = train_model(ensemble.RandomForestClassifier(), xTrca, yTrainAuthor, xTeca,yTestAuthor)\n",
    "print(\"Author, Count Vectors: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['TC']= df.title.str.cat(df['comments'].astype('str'),sep = \" \")\n",
    "df['TCB'] = df.TC.str.cat(df['body'].astype('str'),sep = \" \")\n",
    "df['TCBC'] = df.TCB.str.cat(df['time'].astype('str'),sep=\" \")\n",
    "df['TCBU']=df.TCB.str.cat(df.url.astype('str'),sep = \" \")\n",
    "df['TCBUC']=df.TCBU.str.cat(df.time.astype('str'),sep=\" \")\n",
    "df['TCBUA']=df.TCBU.str.cat(df.author.astype('str'),sep = \" \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "fTCB = df.TCB\n",
    "fTC = df.TC\n",
    "fTCBU = df.TCBU\n",
    "fTCBUA = df.TCBUA\n",
    "fTCBC = df.TCBC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "flairs = [\"AskIndia\", \"Non-Political\", \"[R]eddiquette\", \"Scheduled\", \"Photography\", \"Science/Technology\", \"Politics\", \"Business/Finance\", \"Policy/Economy\", \"Sports\", \"Food\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Title Comment Body Created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = Pipeline([('vect', CountVectorizer()),\n",
    "               ('tfidf', TfidfTransformer()),\n",
    "               ('clf', LogisticRegression()),\n",
    "              ])\n",
    "\n",
    "lr2 = Pipeline([('vect', TfidfVectorizer()),\n",
    "               ('tfidf', TfidfTransformer()),\n",
    "               ('clf', LogisticRegression()),\n",
    "              ])\n",
    "\n",
    "\n",
    "\n",
    "nb = Pipeline([('vect', CountVectorizer()),\n",
    "               ('tfidf', TfidfTransformer()),\n",
    "               ('clf', MultinomialNB()),\n",
    "              ])\n",
    "\n",
    "nb2 = Pipeline([('vect', TfidfVectorizer()),\n",
    "               ('tfidf', TfidfTransformer()),\n",
    "               ('clf', MultinomialNB()),\n",
    "              ])\n",
    "\n",
    "rf =  Pipeline([('vect', CountVectorizer()),\n",
    "               ('tfidf', TfidfTransformer()),\n",
    "               ('clf', RandomForestClassifier()),\n",
    "              ])\n",
    "\n",
    "rf2 = Pipeline([('vect', TfidfVectorizer()),\n",
    "               ('tfidf', TfidfTransformer()),\n",
    "               ('clf', RandomForestClassifier()),\n",
    "              ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\utsavs~1\\desktop\\reddit~1\\myenv\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\utsavs~1\\desktop\\reddit~1\\myenv\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "c:\\users\\utsavs~1\\desktop\\reddit~1\\myenv\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\utsavs~1\\desktop\\reddit~1\\myenv\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "c:\\users\\utsavs~1\\desktop\\reddit~1\\myenv\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "c:\\users\\utsavs~1\\desktop\\reddit~1\\myenv\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOG accuracy 0.5867269984917044\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          AskIndia       0.53      0.59      0.56        69\n",
      "     Non-Political       0.61      0.36      0.45        70\n",
      "     [R]eddiquette       0.82      0.78      0.80        46\n",
      "         Scheduled       0.33      0.41      0.36        64\n",
      "       Photography       0.70      0.89      0.78        45\n",
      "Science/Technology       0.49      0.64      0.56        61\n",
      "          Politics       0.50      0.75      0.60        65\n",
      "  Business/Finance       0.80      0.85      0.83        48\n",
      "    Policy/Economy       0.64      0.47      0.54        60\n",
      "            Sports       0.88      0.89      0.89        57\n",
      "              Food       0.39      0.17      0.23        78\n",
      "\n",
      "          accuracy                           0.59       663\n",
      "         macro avg       0.61      0.62      0.60       663\n",
      "      weighted avg       0.59      0.59      0.57       663\n",
      "\n",
      "LOG accuracy LR2 0.5882352941176471\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          AskIndia       0.43      0.57      0.49        69\n",
      "     Non-Political       0.63      0.39      0.48        70\n",
      "     [R]eddiquette       0.80      0.76      0.78        46\n",
      "         Scheduled       0.32      0.44      0.37        64\n",
      "       Photography       0.75      0.84      0.79        45\n",
      "Science/Technology       0.50      0.67      0.57        61\n",
      "          Politics       0.51      0.80      0.63        65\n",
      "  Business/Finance       0.83      0.83      0.83        48\n",
      "    Policy/Economy       0.65      0.47      0.54        60\n",
      "            Sports       0.94      0.89      0.92        57\n",
      "              Food       0.58      0.14      0.23        78\n",
      "\n",
      "          accuracy                           0.59       663\n",
      "         macro avg       0.63      0.62      0.60       663\n",
      "      weighted avg       0.61      0.59      0.57       663\n",
      "\n",
      "LOG accuracy 0.32428355957767724\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          AskIndia       0.16      0.97      0.27        69\n",
      "     Non-Political       0.00      0.00      0.00        70\n",
      "     [R]eddiquette       1.00      0.11      0.20        46\n",
      "         Scheduled       0.29      0.22      0.25        64\n",
      "       Photography       0.94      0.38      0.54        45\n",
      "Science/Technology       0.54      0.46      0.50        61\n",
      "          Politics       0.60      0.38      0.47        65\n",
      "  Business/Finance       0.88      0.62      0.73        48\n",
      "    Policy/Economy       0.91      0.17      0.28        60\n",
      "            Sports       1.00      0.33      0.50        57\n",
      "              Food       0.00      0.00      0.00        78\n",
      "\n",
      "          accuracy                           0.32       663\n",
      "         macro avg       0.57      0.33      0.34       663\n",
      "      weighted avg       0.52      0.32      0.31       663\n",
      "\n",
      "LOG accuracy nb22 0.4494720965309201\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          AskIndia       0.20      0.87      0.32        69\n",
      "     Non-Political       0.56      0.13      0.21        70\n",
      "     [R]eddiquette       0.88      0.46      0.60        46\n",
      "         Scheduled       0.35      0.27      0.30        64\n",
      "       Photography       0.90      0.60      0.72        45\n",
      "Science/Technology       0.49      0.56      0.52        61\n",
      "          Politics       0.56      0.57      0.56        65\n",
      "  Business/Finance       0.87      0.69      0.77        48\n",
      "    Policy/Economy       0.79      0.25      0.38        60\n",
      "            Sports       0.95      0.68      0.80        57\n",
      "              Food       0.86      0.08      0.14        78\n",
      "\n",
      "          accuracy                           0.45       663\n",
      "         macro avg       0.67      0.47      0.48       663\n",
      "      weighted avg       0.65      0.45      0.45       663\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\utsavs~1\\desktop\\reddit~1\\myenv\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOG accuracy 0.3438914027149321\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          AskIndia       0.22      0.41      0.29        69\n",
      "     Non-Political       0.20      0.23      0.21        70\n",
      "     [R]eddiquette       0.51      0.50      0.51        46\n",
      "         Scheduled       0.18      0.20      0.19        64\n",
      "       Photography       0.44      0.71      0.55        45\n",
      "Science/Technology       0.25      0.25      0.25        61\n",
      "          Politics       0.24      0.25      0.24        65\n",
      "  Business/Finance       0.73      0.67      0.70        48\n",
      "    Policy/Economy       0.32      0.18      0.23        60\n",
      "            Sports       0.74      0.61      0.67        57\n",
      "              Food       0.39      0.09      0.15        78\n",
      "\n",
      "          accuracy                           0.34       663\n",
      "         macro avg       0.39      0.37      0.36       663\n",
      "      weighted avg       0.37      0.34      0.34       663\n",
      "\n",
      "LOG accuracy RF2 0.3212669683257919\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          AskIndia       0.33      0.43      0.38        69\n",
      "     Non-Political       0.16      0.19      0.17        70\n",
      "     [R]eddiquette       0.39      0.50      0.44        46\n",
      "         Scheduled       0.15      0.22      0.18        64\n",
      "       Photography       0.42      0.67      0.51        45\n",
      "Science/Technology       0.22      0.28      0.25        61\n",
      "          Politics       0.25      0.23      0.24        65\n",
      "  Business/Finance       0.66      0.56      0.61        48\n",
      "    Policy/Economy       0.33      0.15      0.21        60\n",
      "            Sports       0.78      0.54      0.64        57\n",
      "              Food       0.16      0.05      0.08        78\n",
      "\n",
      "          accuracy                           0.32       663\n",
      "         macro avg       0.35      0.35      0.34       663\n",
      "      weighted avg       0.33      0.32      0.31       663\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xTrtcbu,xTetcbu,yTrtcbu,yTetcbu=train_test_split(fTCBC,label,test_size=0.25)\n",
    "\n",
    "LR = lr.fit(xTrtcbu,y=yTrtcbu)\n",
    "LR2 = lr2.fit(xTrtcbu,y=yTrtcbu)\n",
    "\n",
    "\n",
    "NB = nb.fit(xTrtcbu,y=yTrtcbu)\n",
    "NB2 = nb2.fit(xTrtcbu,y=yTrtcbu)\n",
    "\n",
    "RF = rf.fit(xTrtcbu,y=yTrtcbu)\n",
    "RF2 = rf2.fit(xTrtcbu,y=yTrtcbu)\n",
    "\n",
    "\n",
    "flairs = [\"AskIndia\", \"Non-Political\", \"[R]eddiquette\", \"Scheduled\", \"Photography\", \"Science/Technology\", \"Politics\", \"Business/Finance\", \"Policy/Economy\", \"Sports\", \"Food\"]\n",
    "\n",
    "y_pred = lr.predict(xTetcbu)\n",
    "y_pred2 = lr2.predict(xTetcbu)\n",
    "\n",
    "print('LOG accuracy %s' % accuracy_score(y_pred, yTetcbu))\n",
    "print(classification_report(yTetcbu, y_pred,target_names=flairs))\n",
    "\n",
    "print('LOG accuracy LR2 %s' % accuracy_score(y_pred2, yTetcbu))\n",
    "print(classification_report(yTetcbu, y_pred2,target_names=flairs))\n",
    "\n",
    "y_pred = nb.predict(xTetcbu)\n",
    "y_pred2 = nb2.predict(xTetcbu)\n",
    "\n",
    "print('LOG accuracy %s' % accuracy_score(y_pred, yTetcbu))\n",
    "print(classification_report(yTetcbu, y_pred,target_names=flairs))\n",
    "\n",
    "print('LOG accuracy nb22 %s' % accuracy_score(y_pred2, yTetcbu))\n",
    "print(classification_report(yTetcbu, y_pred2,target_names=flairs))\n",
    "\n",
    "y_pred = rf.predict(xTetcbu)\n",
    "y_pred2 = rf2.predict(xTetcbu)\n",
    "\n",
    "print('LOG accuracy %s' % accuracy_score(y_pred, yTetcbu))\n",
    "print(classification_report(yTetcbu, y_pred,target_names=flairs))\n",
    "\n",
    "print('LOG accuracy RF2 %s' % accuracy_score(y_pred2, yTetcbu))\n",
    "print(classification_report(yTetcbu, y_pred2,target_names=flairs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Title Comments Body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\utsavs~1\\desktop\\reddit~1\\myenv\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\utsavs~1\\desktop\\reddit~1\\myenv\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "c:\\users\\utsavs~1\\desktop\\reddit~1\\myenv\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\utsavs~1\\desktop\\reddit~1\\myenv\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "c:\\users\\utsavs~1\\desktop\\reddit~1\\myenv\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "c:\\users\\utsavs~1\\desktop\\reddit~1\\myenv\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOG accuracy 0.6093514328808446\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          AskIndia       0.48      0.56      0.52        77\n",
      "     Non-Political       0.54      0.40      0.46        65\n",
      "     [R]eddiquette       0.90      0.77      0.83        56\n",
      "         Scheduled       0.46      0.32      0.38        75\n",
      "       Photography       0.84      0.88      0.86        58\n",
      "Science/Technology       0.40      0.68      0.50        50\n",
      "          Politics       0.59      0.61      0.60        67\n",
      "  Business/Finance       0.81      0.92      0.86        48\n",
      "    Policy/Economy       0.61      0.57      0.59        54\n",
      "            Sports       0.86      0.86      0.86        57\n",
      "              Food       0.38      0.32      0.35        56\n",
      "\n",
      "          accuracy                           0.61       663\n",
      "         macro avg       0.62      0.63      0.62       663\n",
      "      weighted avg       0.61      0.61      0.61       663\n",
      "\n",
      "LOG accuracy LR2 0.6003016591251885\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          AskIndia       0.53      0.53      0.53        77\n",
      "     Non-Political       0.60      0.45      0.51        65\n",
      "     [R]eddiquette       0.86      0.68      0.76        56\n",
      "         Scheduled       0.43      0.33      0.38        75\n",
      "       Photography       0.82      0.81      0.82        58\n",
      "Science/Technology       0.40      0.70      0.51        50\n",
      "          Politics       0.47      0.63      0.54        67\n",
      "  Business/Finance       0.87      0.85      0.86        48\n",
      "    Policy/Economy       0.57      0.59      0.58        54\n",
      "            Sports       0.89      0.88      0.88        57\n",
      "              Food       0.42      0.32      0.36        56\n",
      "\n",
      "          accuracy                           0.60       663\n",
      "         macro avg       0.63      0.62      0.61       663\n",
      "      weighted avg       0.61      0.60      0.60       663\n",
      "\n",
      "LOG accuracy 0.37254901960784315\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          AskIndia       0.20      0.91      0.33        77\n",
      "     Non-Political       0.50      0.03      0.06        65\n",
      "     [R]eddiquette       1.00      0.16      0.28        56\n",
      "         Scheduled       0.12      0.05      0.07        75\n",
      "       Photography       1.00      0.29      0.45        58\n",
      "Science/Technology       0.42      0.70      0.53        50\n",
      "          Politics       0.64      0.43      0.52        67\n",
      "  Business/Finance       0.71      0.75      0.73        48\n",
      "    Policy/Economy       0.75      0.11      0.19        54\n",
      "            Sports       0.96      0.44      0.60        57\n",
      "              Food       0.40      0.25      0.31        56\n",
      "\n",
      "          accuracy                           0.37       663\n",
      "         macro avg       0.61      0.38      0.37       663\n",
      "      weighted avg       0.58      0.37      0.35       663\n",
      "\n",
      "LOG accuracy nb2 0.473604826546003\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          AskIndia       0.28      0.83      0.41        77\n",
      "     Non-Political       0.41      0.14      0.21        65\n",
      "     [R]eddiquette       0.91      0.38      0.53        56\n",
      "         Scheduled       0.32      0.16      0.21        75\n",
      "       Photography       0.93      0.48      0.64        58\n",
      "Science/Technology       0.33      0.70      0.45        50\n",
      "          Politics       0.59      0.57      0.58        67\n",
      "  Business/Finance       0.78      0.79      0.78        48\n",
      "    Policy/Economy       0.79      0.20      0.32        54\n",
      "            Sports       0.94      0.77      0.85        57\n",
      "              Food       0.36      0.25      0.29        56\n",
      "\n",
      "          accuracy                           0.47       663\n",
      "         macro avg       0.60      0.48      0.48       663\n",
      "      weighted avg       0.58      0.47      0.47       663\n",
      "\n",
      "LOG accuracy 0.3559577677224736\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          AskIndia       0.29      0.47      0.36        77\n",
      "     Non-Political       0.20      0.23      0.22        65\n",
      "     [R]eddiquette       0.55      0.41      0.47        56\n",
      "         Scheduled       0.22      0.21      0.22        75\n",
      "       Photography       0.44      0.52      0.48        58\n",
      "Science/Technology       0.20      0.28      0.24        50\n",
      "          Politics       0.28      0.24      0.26        67\n",
      "  Business/Finance       0.81      0.73      0.77        48\n",
      "    Policy/Economy       0.28      0.22      0.25        54\n",
      "            Sports       0.84      0.63      0.72        57\n",
      "              Food       0.11      0.05      0.07        56\n",
      "\n",
      "          accuracy                           0.36       663\n",
      "         macro avg       0.38      0.36      0.37       663\n",
      "      weighted avg       0.37      0.36      0.36       663\n",
      "\n",
      "LOG accuracy RF2 0.3438914027149321\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          AskIndia       0.27      0.40      0.32        77\n",
      "     Non-Political       0.24      0.25      0.24        65\n",
      "     [R]eddiquette       0.45      0.34      0.39        56\n",
      "         Scheduled       0.18      0.19      0.18        75\n",
      "       Photography       0.55      0.60      0.57        58\n",
      "Science/Technology       0.27      0.38      0.32        50\n",
      "          Politics       0.33      0.25      0.29        67\n",
      "  Business/Finance       0.76      0.71      0.73        48\n",
      "    Policy/Economy       0.18      0.19      0.18        54\n",
      "            Sports       0.67      0.53      0.59        57\n",
      "              Food       0.09      0.05      0.07        56\n",
      "\n",
      "          accuracy                           0.34       663\n",
      "         macro avg       0.36      0.35      0.35       663\n",
      "      weighted avg       0.35      0.34      0.34       663\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xTrtcbu,xTetcbu,yTrtcbu,yTetcbu=train_test_split(fTCB,label,test_size=0.25)\n",
    "LR = lr.fit(xTrtcbu,y=yTrtcbu)\n",
    "LR2 = lr2.fit(xTrtcbu,y=yTrtcbu)\n",
    "\n",
    "\n",
    "NB = nb.fit(xTrtcbu,y=yTrtcbu)\n",
    "NB2 = nb2.fit(xTrtcbu,y=yTrtcbu)\n",
    "\n",
    "RF = rf.fit(xTrtcbu,y=yTrtcbu)\n",
    "RF2 = rf2.fit(xTrtcbu,y=yTrtcbu)\n",
    "\n",
    "\n",
    "flairs = [\"AskIndia\", \"Non-Political\", \"[R]eddiquette\", \"Scheduled\", \"Photography\", \"Science/Technology\", \"Politics\", \"Business/Finance\", \"Policy/Economy\", \"Sports\", \"Food\"]\n",
    "\n",
    "y_pred = lr.predict(xTetcbu)\n",
    "y_pred2 = lr2.predict(xTetcbu)\n",
    "\n",
    "print('LOG accuracy %s' % accuracy_score(y_pred, yTetcbu))\n",
    "print(classification_report(yTetcbu, y_pred,target_names=flairs))\n",
    "\n",
    "print('LOG accuracy LR2 %s' % accuracy_score(y_pred2, yTetcbu))\n",
    "print(classification_report(yTetcbu, y_pred2,target_names=flairs))\n",
    "\n",
    "y_pred = nb.predict(xTetcbu)\n",
    "y_pred2 = nb2.predict(xTetcbu)\n",
    "\n",
    "print('LOG accuracy %s' % accuracy_score(y_pred, yTetcbu))\n",
    "print(classification_report(yTetcbu, y_pred,target_names=flairs))\n",
    "\n",
    "print('LOG accuracy nb2 %s' % accuracy_score(y_pred2, yTetcbu))\n",
    "print(classification_report(yTetcbu, y_pred2,target_names=flairs))\n",
    "\n",
    "y_pred = rf.predict(xTetcbu)\n",
    "y_pred2 = rf2.predict(xTetcbu)\n",
    "\n",
    "print('LOG accuracy %s' % accuracy_score(y_pred, yTetcbu))\n",
    "print(classification_report(yTetcbu, y_pred,target_names=flairs))\n",
    "\n",
    "print('LOG accuracy RF2 %s' % accuracy_score(y_pred2, yTetcbu))\n",
    "print(classification_report(yTetcbu, y_pred2,target_names=flairs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Title Comments Body Url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\utsavs~1\\desktop\\reddit~1\\myenv\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\utsavs~1\\desktop\\reddit~1\\myenv\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "c:\\users\\utsavs~1\\desktop\\reddit~1\\myenv\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "c:\\users\\utsavs~1\\desktop\\reddit~1\\myenv\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "c:\\users\\utsavs~1\\desktop\\reddit~1\\myenv\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "c:\\users\\utsavs~1\\desktop\\reddit~1\\myenv\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOG accuracy 0.6033182503770739\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          AskIndia       0.43      0.75      0.55        67\n",
      "     Non-Political       0.63      0.35      0.45        74\n",
      "     [R]eddiquette       0.81      0.71      0.76        55\n",
      "         Scheduled       0.54      0.36      0.43        72\n",
      "       Photography       0.76      0.92      0.83        37\n",
      "Science/Technology       0.53      0.66      0.59        65\n",
      "          Politics       0.50      0.58      0.54        65\n",
      "  Business/Finance       0.89      0.81      0.85        58\n",
      "    Policy/Economy       0.49      0.55      0.52        60\n",
      "            Sports       0.78      0.92      0.84        49\n",
      "              Food       0.61      0.31      0.41        61\n",
      "\n",
      "          accuracy                           0.60       663\n",
      "         macro avg       0.63      0.63      0.62       663\n",
      "      weighted avg       0.62      0.60      0.59       663\n",
      "\n",
      "LOG accuracy LR2 0.6018099547511312\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          AskIndia       0.41      0.67      0.51        67\n",
      "     Non-Political       0.52      0.32      0.40        74\n",
      "     [R]eddiquette       0.80      0.73      0.76        55\n",
      "         Scheduled       0.50      0.35      0.41        72\n",
      "       Photography       0.75      0.89      0.81        37\n",
      "Science/Technology       0.55      0.65      0.60        65\n",
      "          Politics       0.43      0.66      0.52        65\n",
      "  Business/Finance       0.98      0.74      0.84        58\n",
      "    Policy/Economy       0.64      0.62      0.63        60\n",
      "            Sports       0.85      0.96      0.90        49\n",
      "              Food       0.62      0.33      0.43        61\n",
      "\n",
      "          accuracy                           0.60       663\n",
      "         macro avg       0.64      0.63      0.62       663\n",
      "      weighted avg       0.62      0.60      0.60       663\n",
      "\n",
      "LOG accuracy 0.33634992458521873\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          AskIndia       0.15      0.97      0.26        67\n",
      "     Non-Political       0.50      0.04      0.07        74\n",
      "     [R]eddiquette       1.00      0.11      0.20        55\n",
      "         Scheduled       0.42      0.07      0.12        72\n",
      "       Photography       1.00      0.49      0.65        37\n",
      "Science/Technology       0.51      0.37      0.43        65\n",
      "          Politics       0.55      0.52      0.54        65\n",
      "  Business/Finance       0.96      0.45      0.61        58\n",
      "    Policy/Economy       0.92      0.18      0.31        60\n",
      "            Sports       1.00      0.47      0.64        49\n",
      "              Food       0.44      0.13      0.20        61\n",
      "\n",
      "          accuracy                           0.34       663\n",
      "         macro avg       0.68      0.35      0.37       663\n",
      "      weighted avg       0.64      0.34      0.34       663\n",
      "\n",
      "LOG accuracy nb22 0.46304675716440424\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          AskIndia       0.21      0.93      0.34        67\n",
      "     Non-Political       0.64      0.12      0.20        74\n",
      "     [R]eddiquette       0.91      0.36      0.52        55\n",
      "         Scheduled       0.55      0.15      0.24        72\n",
      "       Photography       0.93      0.68      0.78        37\n",
      "Science/Technology       0.47      0.55      0.51        65\n",
      "          Politics       0.47      0.58      0.52        65\n",
      "  Business/Finance       0.95      0.62      0.75        58\n",
      "    Policy/Economy       0.95      0.30      0.46        60\n",
      "            Sports       0.89      0.84      0.86        49\n",
      "              Food       0.42      0.18      0.25        61\n",
      "\n",
      "          accuracy                           0.46       663\n",
      "         macro avg       0.67      0.48      0.49       663\n",
      "      weighted avg       0.65      0.46      0.47       663\n",
      "\n",
      "LOG accuracy 0.358974358974359\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          AskIndia       0.35      0.72      0.47        67\n",
      "     Non-Political       0.21      0.23      0.22        74\n",
      "     [R]eddiquette       0.48      0.44      0.46        55\n",
      "         Scheduled       0.27      0.21      0.23        72\n",
      "       Photography       0.46      0.73      0.56        37\n",
      "Science/Technology       0.18      0.17      0.18        65\n",
      "          Politics       0.19      0.15      0.17        65\n",
      "  Business/Finance       0.85      0.59      0.69        58\n",
      "    Policy/Economy       0.38      0.35      0.37        60\n",
      "            Sports       0.71      0.55      0.62        49\n",
      "              Food       0.12      0.07      0.09        61\n",
      "\n",
      "          accuracy                           0.36       663\n",
      "         macro avg       0.38      0.38      0.37       663\n",
      "      weighted avg       0.36      0.36      0.35       663\n",
      "\n",
      "LOG accuracy RF2 0.36199095022624433\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          AskIndia       0.32      0.58      0.41        67\n",
      "     Non-Political       0.21      0.22      0.21        74\n",
      "     [R]eddiquette       0.53      0.47      0.50        55\n",
      "         Scheduled       0.18      0.21      0.19        72\n",
      "       Photography       0.41      0.62      0.49        37\n",
      "Science/Technology       0.29      0.22      0.25        65\n",
      "          Politics       0.29      0.38      0.33        65\n",
      "  Business/Finance       0.85      0.60      0.71        58\n",
      "    Policy/Economy       0.36      0.27      0.31        60\n",
      "            Sports       0.72      0.59      0.65        49\n",
      "              Food       0.12      0.03      0.05        61\n",
      "\n",
      "          accuracy                           0.36       663\n",
      "         macro avg       0.39      0.38      0.37       663\n",
      "      weighted avg       0.37      0.36      0.35       663\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xTrtcbu,xTetcbu,yTrtcbu,yTetcbu=train_test_split(fTCBU,label,test_size=0.25)\n",
    "\n",
    "LR = lr.fit(xTrtcbu,y=yTrtcbu)\n",
    "LR2 = lr2.fit(xTrtcbu,y=yTrtcbu)\n",
    "\n",
    "\n",
    "NB = nb.fit(xTrtcbu,y=yTrtcbu)\n",
    "NB2 = nb2.fit(xTrtcbu,y=yTrtcbu)\n",
    "\n",
    "RF = rf.fit(xTrtcbu,y=yTrtcbu)\n",
    "RF2 = rf2.fit(xTrtcbu,y=yTrtcbu)\n",
    "\n",
    "\n",
    "flairs = [\"AskIndia\", \"Non-Political\", \"[R]eddiquette\", \"Scheduled\", \"Photography\", \"Science/Technology\", \"Politics\", \"Business/Finance\", \"Policy/Economy\", \"Sports\", \"Food\"]\n",
    "\n",
    "y_pred = lr.predict(xTetcbu)\n",
    "y_pred2 = lr2.predict(xTetcbu)\n",
    "\n",
    "print('LOG accuracy %s' % accuracy_score(y_pred, yTetcbu))\n",
    "print(classification_report(yTetcbu, y_pred,target_names=flairs))\n",
    "\n",
    "print('LOG accuracy LR2 %s' % accuracy_score(y_pred2, yTetcbu))\n",
    "print(classification_report(yTetcbu, y_pred2,target_names=flairs))\n",
    "\n",
    "y_pred = nb.predict(xTetcbu)\n",
    "y_pred2 = nb2.predict(xTetcbu)\n",
    "\n",
    "print('LOG accuracy %s' % accuracy_score(y_pred, yTetcbu))\n",
    "print(classification_report(yTetcbu, y_pred,target_names=flairs))\n",
    "\n",
    "print('LOG accuracy nb22 %s' % accuracy_score(y_pred2, yTetcbu))\n",
    "print(classification_report(yTetcbu, y_pred2,target_names=flairs))\n",
    "\n",
    "y_pred = rf.predict(xTetcbu)\n",
    "y_pred2 = rf2.predict(xTetcbu)\n",
    "\n",
    "print('LOG accuracy %s' % accuracy_score(y_pred, yTetcbu))\n",
    "print(classification_report(yTetcbu, y_pred,target_names=flairs))\n",
    "\n",
    "print('LOG accuracy RF2 %s' % accuracy_score(y_pred2, yTetcbu))\n",
    "print(classification_report(yTetcbu, y_pred2,target_names=flairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
